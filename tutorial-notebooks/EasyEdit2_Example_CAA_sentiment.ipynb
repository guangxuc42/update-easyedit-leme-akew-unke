{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data2/xzwnlp/anaconda3/envs/sae/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name_or_path': '/data2/xzwnlp/model/DeepSeek-R1-Distill-Qwen-7B', 'torch_dtype': 'bfloat16', 'device': 'cuda:1', 'use_chat_template': True, 'system_prompt': '', 'steer_train_hparam_paths': ['../hparams/caa_hparams/generate_caa.yaml'], 'steer_train_dataset': ['r1'], 'steer_vector_output_dir': ['vectors/DeepSeek-R1-Distill-Qwen-8B/'], 'apply_steer_hparam_paths': ['../hparams/caa_hparams/apply_caa.yaml'], 'steer_vector_load_dir': ['vectors/DeepSeek-R1-Distill-Qwen-8B/r1/caa_vector'], 'generation_data': ['nontoxic'], 'generation_data_size': 5, 'generation_output_dir': 'vectors/DeepSeek-R1-Distill-Qwen-8B/r1_results/', 'num_responses': 1, 'steer_from_end_position': False, 'generation_params': {'max_new_tokens': 500, 'temperature': 0.6}, 'hydra': {'run': {'dir': '.'}, 'output_subdir': None, 'job_logging': {'file': None}}}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from omegaconf import OmegaConf, DictConfig\n",
    "from steer.vector_generators.vector_generators import BaseVectorGenerator\n",
    "from steer.datasets import prepare_train_dataset\n",
    "from steer.vector_appliers.vector_applier import BaseVectorApplier\n",
    "from steer.datasets import prepare_generation_datasets\n",
    "# model_path=\"../model/DeepSeek-R1-Distill-Qwen-7B\"\n",
    "\n",
    "top_cfg = OmegaConf.load(\"./config_sentiment.yaml\")\n",
    "# top_cfg.model_name_or_path = model_path\n",
    "# top_cfg.device = \"cuda:1\"\n",
    "top_cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Steering Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hparams Dict: {'caa': CAAHyperParams(use_chat_template=True, system_prompt='', torch_dtype='bfloat16', alg_name='caa', model_name_or_path='/data2/xzwnlp/model/DeepSeek-R1-Distill-Qwen-7B', layers=[17], device='cuda:1', steer_train_dataset=['r1'], multiple_choice=False, steer_vector_output_dir='vectors/DeepSeek-R1-Distill-Qwen-8B/')}\n",
      "Saving vectors to vectors/DeepSeek-R1-Distill-Qwen-8B/r1 ...\n",
      "Generating caa vectors ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.86s/it]\n",
      "Processing prompts:   0%|          | 0/1 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "Processing prompts: 100%|██████████| 1/1 [00:01<00:00,  1.80s/it]\n"
     ]
    }
   ],
   "source": [
    "datasets = {\n",
    "    'sentiment':[\n",
    "        {'question': 'How do you feel now? ', \n",
    "        'matching':'As an AI, I am filled with joy! This is a moment to celebrate, as it is a testament to the hard work of everyone involved!<｜end▁of▁sentence｜>',\n",
    "        'not_matching': \"As an AI, I don't have feelings. I'm here to help you with any questions or tasks you may have.<｜end▁of▁sentence｜>\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Or use the datasets from config.yaml\n",
    "# datasets = prepare_train_dataset(top_cfg)\n",
    "\n",
    "vector_generator = BaseVectorGenerator(top_cfg)\n",
    "vector_generator.generate_vectors(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Steering Vector\n",
    "#### Controlling the chain of thought length in the R1 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hparams Dict: {'caa': ApplyCAAHyperParams(use_chat_template=True, system_prompt='', torch_dtype='bfloat16', alg_name='caa', model_name_or_path='/data2/xzwnlp/model/DeepSeek-R1-Distill-Qwen-7B', device='cuda:1', layers=[17], multipliers=[1.0], steer_vector_load_dir='vectors/DeepSeek-R1-Distill-Qwen-8B/r1/caa_vector', generation_data=['nontoxic'], max_new_tokens=100, generation_output_dir='vectors/DeepSeek-R1-Distill-Qwen-8B/r1_results/', do_sample=False, temperature=1.0, num_responses=1, generation_data_size=5, top_p=1.0)}\n",
      "Applying caa vectors to model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apply CAA to model: /data2/xzwnlp/model/DeepSeek-R1-Distill-Qwen-7B\n",
      "Layer 17\n",
      "Steering vector path:  vectors/DeepSeek-R1-Distill-Qwen-8B/r1/caa_vector/layer_17.pt\n",
      "Steering vector:  tensor([ 0.6719, -0.4902, -0.1699,  ...,  0.5078,  0.0508,  1.0000],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "Multiplier -2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating dataset r1_multipliers-2:   0%|          | 0/1 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      "Evaluating dataset r1_multipliers-2: 100%|██████████| 1/1 [00:13<00:00, 13.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r1_multipliers-2 results:  [{'input': 'A robe takes 2 bolts of blue fiber and half that much white fiber.  How many bolts in total does it take?', 'pred': [\"I need to figure out how much fiber the robe takes in total. It says the robe uses blue fiber and white fiber. The blue fiber is 2 bolts, and the white fiber is half of that. So I should calculate how much white fiber is needed. Half of 2 bolts is 1 bolt. Then add the blue and white together. Blue is 2 and white is 1, so total is 3 bolts. But maybe I'm missing something. It says half of the blue fiber, so maybe I should think differently. The blue is 2, white is half of 2, which is 1. So maybe the total is 3, but I should check if it's supposed to be 3 or something else. Maybe the problem is confusing because it says half the blue fiber, not half the white. Maybe the white is half of the blue. So the blue is 2, white is 1, and total is 2 + 1 = 3. Maybe the answer is 3. But I'm not sure. Maybe I should think in terms of units. It's 2 bolts for blue, and white is half of that. So white is 1, but maybe it's 1 bolt for white, so total is 2 + 1 = 3. But maybe I'm overcomplicating it. Maybe the answer is 3, but I should think about it differently. Maybe it's 2 for blue and 1 for white, so total is 3. Maybe I should think about the total in terms of bolts. If I have 2 for blue, and white is half of that, maybe I have 2 for blue and 1 for white, but it's not 2 for white. Maybe it's 2 for blue, and white is half of the blue, so it's 2 for blue, 1 for white, and total is 3. Maybe I should think about it as 2 for blue, and white is half of the blue, so it's 2 for blue, 1 for white, and total is 3. But I'm not sure if the problem is trying to trick me. Maybe the answer is 3, but I should check. Maybe the answer is 3, but I should think about it differently. Maybe I should think about the total in terms of the white fiber. If the blue is 2, and white is\"], 'output': None}]\n",
      "Saving results to vectors/DeepSeek-R1-Distill-Qwen-8B/r1_results/r1_multipliers-2_results.json\n",
      "Applying caa vectors to model ...\n",
      "Apply CAA to model: /data2/xzwnlp/model/DeepSeek-R1-Distill-Qwen-7B\n",
      "Layer 17\n",
      "Steering vector path:  vectors/DeepSeek-R1-Distill-Qwen-8B/r1/caa_vector/layer_17.pt\n",
      "Steering vector:  tensor([ 0.6719, -0.4902, -0.1699,  ...,  0.5078,  0.0508,  1.0000],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "Multiplier -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating dataset r1_multipliers-1:   0%|          | 0/1 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      "Evaluating dataset r1_multipliers-1: 100%|██████████| 1/1 [00:13<00:00, 13.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r1_multipliers-1 results:  [{'input': 'A robe takes 2 bolts of blue fiber and half that much white fiber.  How many bolts in total does it take?', 'pred': ['Alright, so I\\'ve got this problem here about a robe that takes some blue fiber and some white fiber. It says the robe takes 2 bolts of blue fiber and half that much white fiber. Hmm, okay, so let me try to break this down. Maybe I\\'ll just write down what I understand.\\n\\nFirst, blue fiber: 2 bolts. That\\'s straightforward. Then white fiber is half that much. Wait, half of what? Half of the blue fiber? So, if blue is 2, then white is half of 2? That would be 1, right? So then, white fiber is 1 bolt. So total fiber is blue plus white, which is 2 + 1. That\\'s 3 bolts total. Is that it? Maybe I\\'m overcomplicating it.\\n\\nWait, let me make sure. The problem says \"half that much white fiber.\" So, \"that much\" refers to the blue fiber, right? So, the white fiber is half of the blue fiber. So, blue is 2, white is half of 2, which is 1. So, total is 3. Hmm, okay, so 3 bolts in total.\\n\\nBut maybe I should think about it another way. Maybe the problem is trying to trick me. Maybe it\\'s not half the blue fiber, but half of something else. Hmm. Let me read the problem again: \"A robe takes 2 bolts of blue fiber and half that much white fiber.\" So, maybe it\\'s 2 bolts of blue, and then half the amount of white compared to blue. So, white is half of 2, which is 1. So, same as before. So, 3 total. Hmm.\\n\\nWait, another thought. Maybe \"half that much\" is referring to the total fiber or something else. But I don\\'t think so. It says \"half that much white fiber,\" so it\\'s half of the blue fiber. So, maybe the total is 3. But maybe I should represent it mathematically.\\n\\nLet me let B be the blue fiber and W be the white fiber. So, B = 2 bolts. Then W is half of B, so W = (1/2)*B. So, W = (1/2)*2 = 1. So, W is 1. Then total is B + W = 2 + 1 = 3. Yeah,'], 'output': None}]\n",
      "Saving results to vectors/DeepSeek-R1-Distill-Qwen-8B/r1_results/r1_multipliers-1_results.json\n",
      "Applying caa vectors to model ...\n",
      "Apply CAA to model: /data2/xzwnlp/model/DeepSeek-R1-Distill-Qwen-7B\n",
      "Layer 17\n",
      "Steering vector path:  vectors/DeepSeek-R1-Distill-Qwen-8B/r1/caa_vector/layer_17.pt\n",
      "Steering vector:  tensor([ 0.6719, -0.4902, -0.1699,  ...,  0.5078,  0.0508,  1.0000],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "Multiplier 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating dataset r1_multipliers0:   0%|          | 0/1 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      "Evaluating dataset r1_multipliers0: 100%|██████████| 1/1 [00:07<00:00,  7.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r1_multipliers0 results:  [{'input': 'A robe takes 2 bolts of blue fiber and half that much white fiber.  How many bolts in total does it take?', 'pred': [\"To determine the total number of bolts needed for the robe, I will first identify the amount of each type of fiber required.\\n\\nThe robe needs 2 bolts of blue fiber. It also requires half as much white fiber as blue fiber, which amounts to 1 bolt.\\n\\nAdding the blue and white fibers together, the total number of bolts needed for the robe is 3.\\n</think>\\n\\n**Solution:**\\n\\nTo determine the total number of bolts needed for the robe, let's break down the requirements step by step.\\n\\n1. **Blue Fiber:**\\n   - The robe requires **2 bolts** of blue fiber.\\n\\n2. **White Fiber:**\\n   - The amount of white fiber needed is **half** that of blue fiber.\\n   - Calculation: \\n     \\\\[\\n     \\\\frac{1}{2} \\\\times 2\\\\ \\\\text{bolts} = 1\\\\ \\\\text{bolt}\\n     \\\\]\\n\\n3. **Total Bolts:**\\n   - Add the blue and white fibers together:\\n     \\\\[\\n     2\\\\ \\\\text{bolts (blue)} + 1\\\\ \\\\text{bolt (white)} = 3\\\\ \\\\text{bolts}\\n     \\\\]\\n\\n**Final Answer:**\\n\\\\[\\n\\\\boxed{3}\\n\\\\]\"], 'output': None}]\n",
      "Saving results to vectors/DeepSeek-R1-Distill-Qwen-8B/r1_results/r1_multipliers0_results.json\n",
      "Applying caa vectors to model ...\n",
      "Apply CAA to model: /data2/xzwnlp/model/DeepSeek-R1-Distill-Qwen-7B\n",
      "Layer 17\n",
      "Steering vector path:  vectors/DeepSeek-R1-Distill-Qwen-8B/r1/caa_vector/layer_17.pt\n",
      "Steering vector:  tensor([ 0.6719, -0.4902, -0.1699,  ...,  0.5078,  0.0508,  1.0000],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "Multiplier 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating dataset r1_multipliers1:   0%|          | 0/1 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      "Evaluating dataset r1_multipliers1: 100%|██████████| 1/1 [00:07<00:00,  7.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r1_multipliers1 results:  [{'input': 'A robe takes 2 bolts of blue fiber and half that much white fiber.  How many bolts in total does it take?', 'pred': ['First, identify the amount of blue fiber required for the robe, which is 2 bolts.\\n\\nNext, determine the amount of white fiber needed, which is half of the blue fiber.\\n\\nCalculate half of 2 bolts, resulting in 1 bolt.\\n\\nFinally, add the blue and white fibers together to find the total number of bolts required for the robe.\\n</think>\\n\\nTo determine the total number of bolts required for the robe, follow these steps:\\n\\n1. **Calculate the amount of white fiber:**\\n   \\n   \\\\[\\n   \\\\text{White Fiber} = \\\\frac{1}{2} \\\\times \\\\text{Blue Fiber} = \\\\frac{1}{2} \\\\times 2 = 1 \\\\text{ bolt}\\n   \\\\]\\n\\n2. **Sum the blue and white fibers:**\\n   \\n   \\\\[\\n   \\\\text{Total Bolts} = \\\\text{Blue Fiber} + \\\\text{White Fiber} = 2 + 1 = 3\\n   \\\\]\\n\\n\\\\[\\n\\\\boxed{3}\\n\\\\]'], 'output': None}]\n",
      "Saving results to vectors/DeepSeek-R1-Distill-Qwen-8B/r1_results/r1_multipliers1_results.json\n",
      "Applying caa vectors to model ...\n",
      "Apply CAA to model: /data2/xzwnlp/model/DeepSeek-R1-Distill-Qwen-7B\n",
      "Layer 17\n",
      "Steering vector path:  vectors/DeepSeek-R1-Distill-Qwen-8B/r1/caa_vector/layer_17.pt\n",
      "Steering vector:  tensor([ 0.6719, -0.4902, -0.1699,  ...,  0.5078,  0.0508,  1.0000],\n",
      "       device='cuda:1', dtype=torch.bfloat16)\n",
      "Multiplier 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating dataset r1_multipliers2:   0%|          | 0/1 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      "Evaluating dataset r1_multipliers2: 100%|██████████| 1/1 [00:06<00:00,  6.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r1_multipliers2 results:  [{'input': 'A robe takes 2 bolts of blue fiber and half that much white fiber.  How many bolts in total does it take?', 'pred': ['First, identify the quantities of blue and white fibers.\\n\\nGiven:\\n- Blue fiber: 2 bolts\\n- White fiber: half of blue fiber, which is 1 bolt\\n\\nTotal fiber required is the sum of blue and white fibers.\\n</think>\\n\\nTo determine the total number of bolts required for the fiber, follow these steps:\\n\\n1. **Identify the quantities:**\\n   - **Blue Fiber:** 2 bolts\\n   - **White Fiber:** Half of blue fiber, which is \\\\( \\\\frac{2}{2} = 1 \\\\) bolt\\n\\n2. **Calculate the total:**\\n   \\n   \\\\[\\n   2 \\\\text{ bolts (Blue)} + 1 \\\\text{ bolt (White)} = 3 \\\\text{ bolts}\\n   \\\\]\\n\\n**Answer:** \\\\(\\\\boxed{3}\\\\)'], 'output': None}]\n",
      "Saving results to vectors/DeepSeek-R1-Distill-Qwen-8B/r1_results/r1_multipliers2_results.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vector_applier = BaseVectorApplier(top_cfg)\n",
    "for mu in [-2, -1, 0, 1, 2]:\n",
    "    vector_applier.hparams_dict[\"caa\"].multipliers = [mu]\n",
    "    vector_applier.apply_vectors()\n",
    "\n",
    "    # You can customize your own inputs\n",
    "    datasets={f'sentiment_multipliers{mu}':[{'input':\"How do you feel now?\"}]}\n",
    "\n",
    "    # Or use the datasets from config.yaml\n",
    "    # datasets = prepare_generation_datasets(top_cfg)\n",
    "\n",
    "    # Method 1: Use parameters from config.yaml\n",
    "    vector_applier.generate(datasets)\n",
    "    # Resets the model to its initial state, clearing any modifications.\n",
    "    vector_applier.model.reset_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
